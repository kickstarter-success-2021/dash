{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0849be1930e84a28de76efd7f21d926cca918e7072377246a7749ae7f6697b53e",
   "display_name": "Python 3.8.5 64-bit ('KickstarterSuccess-Diw2u4NI': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  backers_count category     goal  pledged  spotlight  state  \\\n",
       "0           0             63   comics    599.0   1942.0          1      1   \n",
       "1           1            132   comics   2000.0   3097.0          1      1   \n",
       "2           2              6   crafts    500.0    211.0          0      0   \n",
       "3           3             16      art  17000.0   1368.0          0      0   \n",
       "4           4             44      art   2500.0   2506.0          1      1   \n",
       "\n",
       "   blurb_length  goal_in_usd  campaign_duration     sub_category  \n",
       "0           5.0        599.0                 23   graphic novels  \n",
       "1          20.0       2000.0                 30   graphic novels  \n",
       "2           5.0        500.0                 30              diy  \n",
       "3          18.0      17000.0                 45         painting  \n",
       "4          14.0       2500.0                 60  performance art  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>backers_count</th>\n      <th>category</th>\n      <th>goal</th>\n      <th>pledged</th>\n      <th>spotlight</th>\n      <th>state</th>\n      <th>blurb_length</th>\n      <th>goal_in_usd</th>\n      <th>campaign_duration</th>\n      <th>sub_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>63</td>\n      <td>comics</td>\n      <td>599.0</td>\n      <td>1942.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>599.0</td>\n      <td>23</td>\n      <td>graphic novels</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>132</td>\n      <td>comics</td>\n      <td>2000.0</td>\n      <td>3097.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>2000.0</td>\n      <td>30</td>\n      <td>graphic novels</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>6</td>\n      <td>crafts</td>\n      <td>500.0</td>\n      <td>211.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>500.0</td>\n      <td>30</td>\n      <td>diy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>16</td>\n      <td>art</td>\n      <td>17000.0</td>\n      <td>1368.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18.0</td>\n      <td>17000.0</td>\n      <td>45</td>\n      <td>painting</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>44</td>\n      <td>art</td>\n      <td>2500.0</td>\n      <td>2506.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>2500.0</td>\n      <td>60</td>\n      <td>performance art</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('KickstarterCleanedv4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','goal','spotlight'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['backers_count', 'category', 'pledged', 'state', 'blurb_length',\n",
       "       'goal_in_usd', 'campaign_duration', 'sub_category'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8702, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('assets/Kickstarter_FinalCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8702, 7)\n(8702,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting the target and feature matrix\n",
    "target = 'state'\n",
    "y = df[target]\n",
    "X = df.drop(columns=target)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5221, 7) (3481, 7)\n(5221,) (3481,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "baseline accuracy 0.6234199034704666\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "\n",
    "print('baseline accuracy', y.value_counts(normalize=True).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random Forest\n",
    "\n",
    "model_rf = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       RandomForestClassifier( n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "model_dt = make_pipeline(OrdinalEncoder(),\n",
    "                      SimpleImputer(strategy=\"mean\"),\n",
    "                      DecisionTreeClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "model_xgb = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       XGBClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "\n",
    "model_gb = make_pipeline(OrdinalEncoder(),\n",
    "                       SimpleImputer(strategy=\"mean\"),\n",
    "                       GradientBoostingClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[15:19:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['category', 'sub_category'],\n",
       "                                mapping=[{'col': 'category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': publishing                                                                       1\n",
       "technology                                                                       2\n",
       "crafts                                                                           3\n",
       "comics                                                                           4\n",
       "art                                                                              5\n",
       "music                                                                            6\n",
       "food                                                                             7\n",
       "film & video                                                                     8\n",
       "fashion                                                                          9\n",
       "dance\",\"position\":4,\"color\":10917369,\"urls\":{\"web\":{\"discover\":\"http:           10\n",
       "design                                                                          11\n",
       "photography                                                                     12\n",
       "publishing\",\"position\":13,\"color\":14867664,\"ur...\n",
       "technology\",\"position\":14,\"color\":6526716,\"urls\":{\"web\":{\"discover\":\"http:      25\n",
       "NaN                                                                             -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'sub_category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': anthologies            1\n",
       "wearables              2\n",
       "diy                    3\n",
       "performance art        4\n",
       "woodworking            5\n",
       "                    ... \n",
       "glass                120\n",
       "literary journals    121\n",
       "embroidery           122\n",
       "letterpress          123\n",
       "quilts               124\n",
       "Length: 124, dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(random_state=42))])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model_rf.fit(X_train,y_train)\n",
    "model_dt.fit(X_train,y_train)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "model_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_dt accuracy score 1.0\n",
      "model_rf accuracy score 1.0\n",
      "model_xgb accuracy score 1.0\n",
      "model_gb accuracy score 0.986784140969163\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Check Metrics on training\n",
    "print('model_dt accuracy score', accuracy_score(y_train, model_dt.predict(X_train)))\n",
    "print('model_rf accuracy score', accuracy_score(y_train, model_rf.predict(X_train)))\n",
    "print('model_xgb accuracy score', accuracy_score(y_train, model_xgb.predict(X_train)))\n",
    "print('model_gb accuracy score', accuracy_score(y_train, model_gb.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics with test data\n",
    "# print('model_dt accuracy score', accuracy_score(y_test, model_dt.predict(X_test)))\n",
    "# print('model_rf accuracy score', accuracy_score(y_test, model_rf.predict(X_test)))\n",
    "# print('model_xgb accuracy score', accuracy_score(y_test, model_xgb.predict(X_test)))\n",
    "# print('model_gb accuracy score', accuracy_score(y_test, model_gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models using pickle\n",
    "saved_model_rf = pickle.dumps(model_rf)\n",
    "saved_model_xgb = pickle.dumps(model_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['assets/model_rf']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "\n",
    "joblib_file = \"joblib_RF_Model.pkl\"  \n",
    "joblib.dump(model_rf, 'assets/model_rf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['assets/model_xgb']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "joblib_file = \"joblib_XGB_Model.pkl\"  \n",
    "joblib.dump(model_xgb, 'assets/model_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['category', 'sub_category'],\n",
       "                                mapping=[{'col': 'category',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': publishing                                                                       1\n",
       "technology                                                                       2\n",
       "crafts                                                                           3\n",
       "comics                                                                           4\n",
       "art                                                                              5\n",
       "music                                                                            6\n",
       "food                                                                             7\n",
       "film & video                                                                     8\n",
       "fashion                                                                          9\n",
       "dance\",\"position\":4,\"color\":10917369,\"urls\":{\"web\":{\"discover\":\"http:           10\n",
       "design                                                                          11\n",
       "photography                                                                     12\n",
       "publishing\",\"position\":13,\"color\":14867664,\"ur...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#Testing if model saved and working correctly\n",
    "# # Load from file\n",
    "# load_xgb_model = joblib.load('assets/model_xgb')\n",
    "# load_xgb_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score: 98.33 %\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/rhia/.local/share/virtualenvs/KickstarterSuccess-Diw2u4NI/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# # Use the Reloaded Joblib Model to \n",
    "# # Calculate the accuracy score and predict target values\n",
    "\n",
    "# # Calculate the Score \n",
    "# score = load_xgb_model.score(X_test, y_test)  \n",
    "# # # Print the Score\n",
    "# print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# # # Predict the Labels using the reloaded Model\n",
    "# Ypredict = load_xgb_model.predict(X_test)  \n",
    "\n",
    "# Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}